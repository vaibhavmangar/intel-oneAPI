{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696fbc61-20e7-40f0-8970-297b2f14664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting intel-extension-for-tensorflow\n",
      "  Downloading intel_extension_for_tensorflow-2.14.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m255.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /home/u397376632f7c192901c58bc2f6338e9/.local/lib/python3.9/site-packages (from intel-extension-for-tensorflow) (1.60.1)\n",
      "Requirement already satisfied: wheel in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel-extension-for-tensorflow) (0.40.0)\n",
      "Collecting tensorflow~=2.14.0 (from intel-extension-for-tensorflow)\n",
      "  Downloading tensorflow-2.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m474.8/489.9 MB\u001b[0m \u001b[31m135.9 kB/s\u001b[0m eta \u001b[36m0:01:51\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install intel-extension-for-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9790111-cb8c-42ad-8b7d-9b8dbdaaa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from intel_extension_for_tensorflow import core as intel_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b858e87-53da-4d93-8ad8-d0ade8481cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c788b56-114a-4bdd-812f-d85431e6b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3ba09-df6f-4349-8ab5-5864df51db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33fb3d2-6906-4460-b33f-e97b54a6a705",
   "metadata": {},
   "source": [
    "**Reading and Displaying the 4000 stories Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa04b9-4233-4554-b02d-377928d35a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"4000-Stories-with-sentiment-analysis.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01af25-47a7-4b14-ac15-daef37d62d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04503f73-abd6-4505-972c-17a21495f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de35ba1-8818-412f-bc9f-27491f09ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7113a4-f8ab-4c15-b82c-b6bc858c355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847850f9-96fe-4fed-b9a8-0697630d099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd3c7b-8f53-4cb2-9d03-7b699b8b9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8418c-4f44-4e94-91bc-27d479e2e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec4468-f6a5-4dbc-9713-f5da5dfb48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364337d-1fc3-42e1-851a-3e054f05fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea4a41-e5f9-4e46-b72a-96e93e311813",
   "metadata": {},
   "source": [
    "**Dropping Irrelevant Column from the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49becf7-c8b4-4980-a450-de082898798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['',''], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a21094e-15f8-41b8-a9a1-e92f049f0c9b",
   "metadata": {},
   "source": [
    "**Explorartory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09aa39b-89b6-4bb7-939b-e2e5e6f1da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df[['','','','']].corr()\n",
    "sns.heatmap(correlation,annot=True,cmap='Greens')\n",
    "plt.title('Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23500a-86f2-4176-9cf9-aab532f39069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # text cleaning and preprocessing steps\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69c353-75f9-4562-8e11-a6b3fdc0f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text_data = [preprocess_text(text) for text in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75b34d-5c98-49e4-b94a-16223b68e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=10000)  \n",
    "tokenizer.fit_on_texts(processed_text_data)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(processed_text_data)\n",
    "sequences = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=100)  \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "index_to_word = {index: word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948d8a4-e0b8-4b69-abd3-14cff0fda6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model with oneAPI optimizations\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(10000, 128, input_length=100))  \n",
    "    model.add(LSTM(64, return_sequences=True))  \n",
    "    model.add(LSTM(32))  \n",
    "    model.add(Dense(10000, activation='softmax'))\n",
    "\n",
    "    # Optimize for oneAPI and Gemini architecture using intel_ext.convert\n",
    "    model = intel_ext.convert(model)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab409d7a-f65b-4abc-b4b8-300ab74566df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimized model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab1d4b-58b5-4182-91c7-2647f12dc29e",
   "metadata": {},
   "source": [
    "**Split Data and Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a3da6-67a1-4ee8-bd69-aa7b661c92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sckit-learn-intelex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b80868-f9a4-400c-b69b-f81378ffe60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95382f8c-f853-46fa-9d97-860df29f94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['','']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c8d1f-408c-45bc-bd36-d5d43ff7c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac0607-00c1-442b-b05c-e072fb81f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc83d7d-f121-4bcd-932f-5a59d488919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b2881-1b42-44c4-af73-dab6bd144b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f3777-231f-4ddf-8a00-afbe54336a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01876c2c-92ba-4a57-a49d-c670316fb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db1ac0-470a-4c4e-a46c-f8fa1125202a",
   "metadata": {},
   "source": [
    "**Evaluate Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8b6c6-107b-4db1-acd5-98d97bf26c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6432d-dfc0-4a4e-b4d6-8df7142567b3",
   "metadata": {},
   "source": [
    "**Generate Creative Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b3961-a349-40fd-a905-1a425d2f506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text based on a prompt\n",
    "def generate_text(prompt, max_length=100, temperature=0.7):\n",
    "    # Seed the model with the prompt\n",
    "    seed = tokenizer.texts_to_sequences([prompt])[0]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Predict the next word\n",
    "        probs = model.predict(np.array([seed]))[0]\n",
    "        next_index = np.random.choice(np.arange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f7cf4-a8d1-4e45-b06a-b20241071d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
